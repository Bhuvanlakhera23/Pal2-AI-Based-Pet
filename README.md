PAL2: PHYSICAL AI DESKTOP ASSISTANT

Pal2 is a lightweight AI-powered digital pet that can talk to you via typed or voice interactions!
It uses AIML (Artificial Intelligence Markup Language) for conversation, and supports TTS (Text-to-Speech) for natural voice responses. This version of Pal2 contains the basic fed AIML conversational capabilities, which will be replaced by NLP in future versions. The ultimate goal is to load Pal2 to a physical microcontroller with more capabilities, like Emotion Recognition and improved awareness.

âœ¨ Features
ğŸ§  AIML Brain: Pre-trained conversational responses.

ğŸ¤ Voice & Text Mode: Talk by typing or speaking.

ğŸ—£ï¸ Natural Voice Responses: Powered by Coqui TTS (Jenny Model).

ğŸ”„ Hot Reload: AIML files update without restarting.

ğŸ–¥ï¸ Lightweight: TTS runs without a GPU; use a GPU for faster responses.

ğŸš€ Setup
1) Clone the repo:
    git clone https://github.com/Bhuvanlakhera23/Pal2-AI-Based-Pet.git
    cd Pal2-AI-Based-Pet

2) Create a virtual environment:
    python -m venv venv-gpu

3) Activate the environment:
    Windows:
    venv-gpu\Scripts\activate

    Linux/Mac:
    source venv-gpu/bin/activate

4) Install requirements:
    pip install -r requirements.txt

5) Run Pal2:
    python main.py

NOTE: 
Hot Reload Notes
- On first run, `brain.brn` will be auto-generated from AIML files.
- Delete this file to force a full AIML reload.
    

ğŸ› ï¸ Project Structure
PAL2/
â”œâ”€â”€ aiml_data/          # AIML knowledge base
â”œâ”€â”€ config/             # Settings files
â”œâ”€â”€ core/               # Main program logic
â”œâ”€â”€ brain.brn           # Saved AIML brain cache
â”œâ”€â”€ coqui_tts.py        # TTS Integration
â”œâ”€â”€ main.py             # Program Entry Point
â”œâ”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ README.md           # This file
â””â”€â”€ .gitignore          # Files to ignore

ğŸ“š Technologies Used
Python 3.11+
AIML (python-aiml)
Coqui TTS
SpeechRecognition
Pyttsx3 (fallback if no GPU)
Watchdog (Allows instant changes in AIML responses without restarting Main.py)

ğŸ¯ Future Plans
Add emotion responses.
Movement animations (After connecting to the hardware).
Smarter NLP with intent detection.

ğŸ¤ Contributions
PRs are welcome. Feel free to fork.

ğŸ“œ License
This project is open-source and available under the MIT License.
